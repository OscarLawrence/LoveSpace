{
  "project": "knowledge",
  "success": false,
  "total_checks": 5,
  "passed": 0,
  "failed": 5,
  "failures": [
    {
      "check": "Test Execution",
      "error": "Tests failed: ERROR: usage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --cov=src --cov-report=json --cov-report=term\n  inifile: /home/vincent/Documents/Momo/WorkSpace/projects/core/knowledge/pyproject.toml\n  rootdir: /home/vincent/Documents/Momo/WorkSpace/projects/core/knowledge\n\n"
    },
    {
      "check": "Ruff Linting",
      "error": "Linting issues: F401 [*] `typing.Dict` imported but unused\n --> src/knowledge/batch_embeddings.py:7:26\n  |\n5 | \"\"\"\n6 |\n7 | from typing import List, Dict, Set, Tuple, Optional\n  |                          ^^^^\n8 | from dataclasses import dataclass\n9 | import numpy as np\n  |\nhelp: Remove unused import\n\nF401 [*] `typing.Set` imported but unused\n --> src/knowledge/batch_embeddings.py:7:32\n  |\n5 | \"\"\"\n6 |\n7 | from typing import List, Dict, Set, Tuple, Optional\n  |                                ^^^\n8 | from dataclasses import dataclass\n9 | import numpy as np\n  |\nhelp: Remove unused import\n\nF401 [*] `typing.Tuple` imported but unused\n --> src/knowledge/batch_embeddings.py:7:37\n  |\n5 | \"\"\"\n6 |\n7 | from typing import List, Dict, Set, Tuple, Optional\n  |                                     ^^^^^\n8 | from dataclasses import dataclass\n9 | import numpy as np\n  |\nhelp: Remove unused import\n\nF401 [*] `typing.Optional` imported but unused\n --> src/knowledge/batch_embeddings.py:7:44\n  |\n5 | \"\"\"\n6 |\n7 | from typing import List, Dict, Set, Tuple, Optional\n  |                                            ^^^^^^^^\n8 | from dataclasses import dataclass\n9 | import numpy as np\n  |\nhelp: Remove unused import\n\nF841 Local variable `selected_format` is assigned to but never used\n  --> src/knowledge/batch_embeddings.py:57:9\n   |\n55 |             BatchResult with combined context data\n56 |         \"\"\"\n57 |         selected_format = self.formatter.select_format(context, format_type)\n   |         ^^^^^^^^^^^^^^^\n58 |         \n59 |         # Batch embedding calculation\n   |\nhelp: Remove assignment to unused variable `selected_format`\n\nE722 Do not use bare `except`\n   --> src/knowledge/batch_embeddings.py:253:13\n    |\n251 |             try:\n252 |                 params = json.loads(params_json) if params_json else []\n253 |             except:\n    |             ^^^^^^\n254 |                 params = []\n    |\n\nF401 [*] `ast` imported but unused\n --> src/knowledge/dense_descriptions.py:3:8\n  |\n1 | \"\"\"Dense description generator for functions and code patterns.\"\"\"\n2 |\n3 | import ast\n  |        ^^^\n4 | import re\n5 | from typing import Dict, List, Set, Optional\n  |\nhelp: Remove unused import: `ast`\n\nF401 [*] `typing.Dict` imported but unused\n --> src/knowledge/dense_descriptions.py:5:20\n  |\n3 | import ast\n4 | import re\n5 | from typing import Dict, List, Set, Optional\n  |                    ^^^^\n6 | from .db_manager import Function, Pattern\n  |\nhelp: Remove unused import\n\nF401 [*] `typing.Set` imported but unused\n --> src/knowledge/dense_descriptions.py:5:32\n  |\n3 | import ast\n4 | import re\n5 | from typing import Dict, List, Set, Optional\n  |                                ^^^\n6 | from .db_manager import Function, Pattern\n  |\nhelp: Remove unused import\n\nF841 Local variable `code_lower` is assigned to but never used\n   --> src/knowledge/dense_descriptions.py:305:9\n    |\n303 |         \"\"\"Analyze code snippet for semantic patterns.\"\"\"\n304 |         patterns = []\n305 |         code_lower = code.lower()\n    |         ^^^^^^^^^^\n306 |         \n307 |         # Check for common code patterns\n    |\nhelp: Remove assignment to unused variable `code_lower`\n\nF401 [*] `typing.Optional` imported but unused\n --> src/knowledge/embeddings.py:5:26\n  |\n3 | import os\n4 | import numpy as np\n5 | from typing import List, Optional\n  |                          ^^^^^^^^\n6 | from sentence_transformers import SentenceTransformer\n7 | import os\n  |\nhelp: Remove unused import: `typing.Optional`\n\nF811 [*] Redefinition of unused `os` from line 3\n --> src/knowledge/embeddings.py:7:8\n  |\n5 | from typing import List, Optional\n6 | from sentence_transformers import SentenceTransformer\n7 | import os\n  |        ^^\n8 |\n9 | try:\n  |\nhelp: Remove definition: `os`\n\nF401 [*] `typing.List` imported but unused\n --> src/knowledge/enhanced_patterns.py:7:20\n  |\n5 | \"\"\"\n6 |\n7 | from typing import List\n  |                    ^^^^\n8 | from .db_manager import Pattern\n9 | from .patterns import get_enhanced_patterns\n  |\nhelp: Remove unused import: `typing.List`\n\nF401 [*] `.db_manager.Pattern` imported but unused\n --> src/knowledge/enhanced_patterns.py:8:25\n  |\n7 | from typing import List\n8 | from .db_manager import Pattern\n  |                         ^^^^^^^\n9 | from .patterns import get_enhanced_patterns\n  |\nhelp: Remove unused import: `.db_manager.Pattern`\n\nF401 [*] `asyncio` imported but unused\n --> src/knowledge/feedback_loop.py:6:8\n  |\n4 | \"\"\"\n5 |\n6 | import asyncio\n  |        ^^^^^^^\n7 | import time\n8 | from typing import Dict, List, Any, Optional, Tuple\n  |\nhelp: Remove unused import: `asyncio`\n\nF401 [*] `typing.Optional` imported but unused\n  --> src/knowledge/feedback_loop.py:8:37\n   |\n 6 | import asyncio\n 7 | import time\n 8 | from typing import Dict, List, Any, Optional, Tuple\n   |                                     ^^^^^^^^\n 9 | from collections import deque, defaultdict\n10 | import numpy as np\n   |\nhelp: Remove unused import\n\nF401 [*] `typing.Tuple` imported but unused\n  --> src/knowledge/feedback_loop.py:8:47\n   |\n 6 | import asyncio\n 7 | import time\n 8 | from typing import Dict, List, Any, Optional, Tuple\n   |                                               ^^^^^\n 9 | from collections import deque, defaultdict\n10 | import numpy as np\n   |\nhelp: Remove unused import\n\nF821 Undefined name `OptimizationStrategy`\n  --> src/knowledge/feedback_loop.py:54:60\n   |\n53 |     async def process_feedback(self, metrics_history: deque,\n54 |                              active_strategies: Dict[str, 'OptimizationStrategy']) -> None:\n   |                                                            ^^^^^^^^^^^^^^^^^^^^\n55 |         \"\"\"Process performance feedback and adapt strategies\"\"\"\n56 |         if not metrics_history or len(metrics_history) < 2:\n   |\n\nF821 Undefined name `OptimizationStrategy`\n  --> src/knowledge/feedback_loop.py:74:72\n   |\n73 |     async def _analyze_performance_changes(self, metrics_history: deque,\n74 |                                          active_strategies: Dict[str, 'OptimizationStrategy']) -> None:\n   |                                                                        ^^^^^^^^^^^^^^^^^^^^\n75 |         \"\"\"Analyze performance changes and correlate with strategy usage\"\"\"\n76 |         if len(metrics_history) < 10:\n   |\n\nF821 Undefined name `PerformanceMetrics`\n   --> src/knowledge/feedback_loop.py:105:58\n    |\n103 |     async def _correlate_with_strategies(self, improvements: Dict[str, float],\n104 |                                        overall_improvement: float,\n105 |                                        current_metrics: 'PerformanceMetrics',\n    |                                                          ^^^^^^^^^^^^^^^^^^\n106 |                                        active_strategies: Dict[str, 'OptimizationStrategy']) -> None:\n107 |         \"\"\"Correlate performance improvements with strategy usage\"\"\"\n    |\n\nF821 Undefined name `OptimizationStrategy`\n   --> src/knowledge/feedback_loop.py:106:70\n    |\n104 |                                        overall_improvement: float,\n105 |                                        current_metrics: 'PerformanceMetrics',\n106 |                                        active_strategies: Dict[str, 'OptimizationStrategy']) -> None:\n    |                                                                      ^^^^^^^^^^^^^^^^^^^^\n107 |         \"\"\"Correlate performance improvements with strategy usage\"\"\"\n    |\n\nF821 Undefined name `OptimizationStrategy`\n   --> src/knowledge/feedback_loop.py:254:80\n    |\n252 |             self.adaptation_rules = self.adaptation_rules[:20]\n253 |     \n254 |     async def _apply_learned_optimizations(self, active_strategies: Dict[str, 'OptimizationStrategy']) -> None:\n    |                                                                                ^^^^^^^^^^^^^^^^^^^^\n255 |         \"\"\"Apply learned optimizations to active strategies\"\"\"\n    |\n\nF401 [*] `typing.Any` imported but unused\n  --> src/knowledge/format_manager.py:10:42\n   |\n 8 | import re\n 9 | from enum import Enum\n10 | from typing import Dict, List, Optional, Any\n   |                                          ^^^\n11 | from dataclasses import dataclass\n   |\nhelp: Remove unused import: `typing.Any`\n\nF401 [*] `asyncio` imported but unused\n --> src/knowledge/optimization/optimization_engine.py:6:8\n  |\n4 | \"\"\"\n5 |\n6 | import asyncio\n  |        ^^^^^^^\n7 | import time\n8 | import numpy as np\n  |\nhelp: Remove unused import: `asyncio`\n\nF401 [*] `typing.Optional` imported but unused\n  --> src/knowledge/optimization/optimization_engine.py:9:37\n   |\n 7 | import time\n 8 | import numpy as np\n 9 | from typing import Dict, List, Any, Optional, Tuple\n   |                                     ^^^^^^^^\n10 | from dataclasses import dataclass\n11 | from enum import Enum\n   |\nhelp: Remove unused import: `typing.Optional`\n\nF401 [*] `json` imported but unused\n  --> src/knowledge/optimization/optimization_engine.py:13:8\n   |\n11 | from enum import Enum\n12 | from collections import deque\n13 | import json\n   |        ^^^^\n   |\nhelp: Remove unused import: `json`\n\nF841 Local variable `current_metrics` is assigned to but never used\n   --> src/knowledge/optimization/optimization_engine.py:136:9\n    |\n134 |                                            analysis: Dict[str, Any]) -> OptimizationDecision:\n135 |         \"\"\"Fast gradient descent optimization for urgent situations\"\"\"\n136 |         current_metrics = context.current_metrics\n    |         ^^^^^^^^^^^^^^^\n137 |         objective = context.optimization_objective\n    |\nhelp: Remove assignment to unused variable `current_metrics`\n\nF841 Local variable `objective` is assigned to but never used\n   --> src/knowledge/optimization/optimization_engine.py:137:9\n    |\n135 |         \"\"\"Fast gradient descent optimization for urgent situations\"\"\"\n136 |         current_metrics = context.current_metrics\n137 |         objective = context.optimization_objective\n    |         ^^^^^^^^^\n138 |         \n139 |         # Calculate gradient direction\n    |\nhelp: Remove assignment to unused variable `objective`\n\nF841 Local variable `current_accuracy` is assigned to but never used\n   --> src/knowledge/optimization/optimization_engine.py:424:9\n    |\n422 |         \"\"\"Estimate expected improvement from parameters\"\"\"\n423 |         # Simplified improvement estimation\n424 |         current_accuracy = context.current_metrics.get(\"accuracy\", 0.8)\n    |         ^^^^^^^^^^^^^^^^\n425 |         \n426 |         # Lower temperature generally improves accuracy\n    |\nhelp: Remove assignment to unused variable `current_accuracy`\n\nF401 [*] `typing.Callable` imported but unused\n  --> src/knowledge/optimizer.py:8:47\n   |\n 6 | import asyncio\n 7 | import time\n 8 | from typing import Dict, List, Any, Optional, Callable\n   |                                               ^^^^^^^^\n 9 | from dataclasses import dataclass, field\n10 | from enum import Enum\n   |\nhelp: Remove unused import: `typing.Callable`\n\nF841 Local variable `update` is assigned to but never used\n   --> src/knowledge/optimizer.py:257:9\n    |\n255 |                                            params: Dict[str, Any]) -> None:\n256 |         \"\"\"Broadcast optimization updates to connected systems\"\"\"\n257 |         update = {\n    |         ^^^^^^\n258 |             \"strategy\": strategy.name,\n259 |             \"parameters\": params,\n    |\nhelp: Remove assignment to unused variable `update`\n\nF821 Undefined name `PerformanceMetrics`\n   --> src/knowledge/performance_monitor.py:122:41\n    |\n120 |         return duration\n121 |     \n122 |     async def collect_metrics(self) -> 'PerformanceMetrics':\n    |                                         ^^^^^^^^^^^^^^^^^^\n123 |         \"\"\"Collect comprehensive performance metrics\"\"\"\n124 |         from .optimizer import PerformanceMetrics\n    |\n\nF401 [*] `asyncio` imported but unused\n --> src/knowledge/strategy_selector.py:6:8\n  |\n4 | \"\"\"\n5 |\n6 | import asyncio\n  |        ^^^^^^^\n7 | from typing import Dict, List, Any, Optional\n8 | import numpy as np\n  |\nhelp: Remove unused import: `asyncio`\n\nF401 [*] `typing.Optional` imported but unused\n --> src/knowledge/strategy_selector.py:7:37\n  |\n6 | import asyncio\n7 | from typing import Dict, List, Any, Optional\n  |                                     ^^^^^^^^\n8 | import numpy as np\n9 | from enum import Enum\n  |\nhelp: Remove unused import: `typing.Optional`\n\nF821 Undefined name `PerformanceMetrics`\n  --> src/knowledge/strategy_selector.py:68:55\n   |\n66 |         }\n67 |     \n68 |     async def select_strategy(self, current_metrics: 'PerformanceMetrics',\n   |                                                       ^^^^^^^^^^^^^^^^^^\n69 |                             available_strategies: Dict[str, 'OptimizationStrategy'],\n70 |                             optimization_mode: 'OptimizationMode') -> 'OptimizationStrategy':\n   |\n\nF821 Undefined name `OptimizationStrategy`\n  --> src/knowledge/strategy_selector.py:69:62\n   |\n68 |     async def select_strategy(self, current_metrics: 'PerformanceMetrics',\n69 |                             available_strategies: Dict[str, 'OptimizationStrategy'],\n   |                                                              ^^^^^^^^^^^^^^^^^^^^\n70 |                             optimization_mode: 'OptimizationMode') -> 'OptimizationStrategy':\n71 |         \"\"\"Select optimal strategy based on current context and performance\"\"\"\n   |\n\nF821 Undefined name `OptimizationMode`\n  --> src/knowledge/strategy_selector.py:70:49\n   |\n68 |     async def select_strategy(self, current_metrics: 'PerformanceMetrics',\n69 |                             available_strategies: Dict[str, 'OptimizationStrategy'],\n70 |                             optimization_mode: 'OptimizationMode') -> 'OptimizationStrategy':\n   |                                                 ^^^^^^^^^^^^^^^^\n71 |         \"\"\"Select optimal strategy based on current context and performance\"\"\"\n   |\n\nF821 Undefined name `OptimizationStrategy`\n  --> src/knowledge/strategy_selector.py:70:72\n   |\n68 |     async def select_strategy(self, current_metrics: 'PerformanceMetrics',\n69 |                             available_strategies: Dict[str, 'OptimizationStrategy'],\n70 |                             optimization_mode: 'OptimizationMode') -> 'OptimizationStrategy':\n   |                                                                        ^^^^^^^^^^^^^^^^^^^^\n71 |         \"\"\"Select optimal strategy based on current context and performance\"\"\"\n   |\n\nF821 Undefined name `PerformanceMetrics`\n  --> src/knowledge/strategy_selector.py:93:49\n   |\n91 |         return selected_strategy\n92 |     \n93 |     def _determine_context_type(self, metrics: 'PerformanceMetrics') -> ContextType:\n   |                                                 ^^^^^^^^^^^^^^^^^^\n94 |         \"\"\"Determine current context type from metrics and environment\"\"\"\n95 |         context_info = metrics.context\n   |\n\nF821 Undefined name `OptimizationStrategy`\n   --> src/knowledge/strategy_selector.py:111:58\n    |\n109 |             return ContextType.GENERAL\n110 |     \n111 |     async def _calculate_strategy_score(self, strategy: 'OptimizationStrategy',\n    |                                                          ^^^^^^^^^^^^^^^^^^^^\n112 |                                       current_metrics: 'PerformanceMetrics',\n113 |                                       context_type: ContextType,\n    |\n\nF821 Undefined name `PerformanceMetrics`\n   --> src/knowledge/strategy_selector.py:112:57\n    |\n111 |     async def _calculate_strategy_score(self, strategy: 'OptimizationStrategy',\n112 |                                       current_metrics: 'PerformanceMetrics',\n    |                                                         ^^^^^^^^^^^^^^^^^^\n113 |                                       context_type: ContextType,\n114 |                                       optimization_mode: 'OptimizationMode') -> float:\n    |\n\nF821 Undefined name `OptimizationMode`\n   --> src/knowledge/strategy_selector.py:114:59\n    |\n112 |                                       current_metrics: 'PerformanceMetrics',\n113 |                                       context_type: ContextType,\n114 |                                       optimization_mode: 'OptimizationMode') -> float:\n    |                                                           ^^^^^^^^^^^^^^^^\n115 |         \"\"\"Calculate comprehensive strategy score\"\"\"\n    |\n\nF821 Undefined name `OptimizationStrategy`\n   --> src/knowledge/strategy_selector.py:143:51\n    |\n141 |         return total_score\n142 |     \n143 |     def _calculate_context_score(self, strategy: 'OptimizationStrategy',\n    |                                                   ^^^^^^^^^^^^^^^^^^^^\n144 |                                context_type: ContextType) -> float:\n145 |         \"\"\"Calculate context-specific strategy score\"\"\"\n    |\n\nF821 Undefined name `OptimizationStrategy`\n   --> src/knowledge/strategy_selector.py:166:59\n    |\n164 |         return (strategy_bias * 0.6 + metric_alignment * 0.4) / 1.6\n165 |     \n166 |     def _calculate_performance_gap_score(self, strategy: 'OptimizationStrategy',\n    |                                                           ^^^^^^^^^^^^^^^^^^^^\n167 |                                        current_metrics: 'PerformanceMetrics') -> float:\n168 |         \"\"\"Calculate score based on performance gaps\"\"\"\n    |\n\nF821 Undefined name `PerformanceMetrics`\n   --> src/knowledge/strategy_selector.py:167:58\n    |\n166 |     def _calculate_performance_gap_score(self, strategy: 'OptimizationStrategy',\n167 |                                        current_metrics: 'PerformanceMetrics') -> float:\n    |                                                          ^^^^^^^^^^^^^^^^^^\n168 |         \"\"\"Calculate score based on performance gaps\"\"\"\n169 |         gap_score = 0.0\n    |\n\nF821 Undefined name `OptimizationStrategy`\n   --> src/knowledge/strategy_selector.py:194:48\n    |\n192 |         return gap_score / total_weight if total_weight > 0 else 0.0\n193 |     \n194 |     def _calculate_mode_score(self, strategy: 'OptimizationStrategy',\n    |                                                ^^^^^^^^^^^^^^^^^^^^\n195 |                             optimization_mode: 'OptimizationMode') -> float:\n196 |         \"\"\"Calculate mode-specific strategy score\"\"\"\n    |\n\nF821 Undefined name `OptimizationMode`\n   --> src/knowledge/strategy_selector.py:195:49\n    |\n194 |     def _calculate_mode_score(self, strategy: 'OptimizationStrategy',\n195 |                             optimization_mode: 'OptimizationMode') -> float:\n    |                                                 ^^^^^^^^^^^^^^^^\n196 |         \"\"\"Calculate mode-specific strategy score\"\"\"\n197 |         from .optimizer import OptimizationMode\n    |\n\nF821 Undefined name `OptimizationStrategy`\n   --> src/knowledge/strategy_selector.py:224:51\n    |\n222 |         return score / total_weight if total_weight > 0 else 0.0\n223 |     \n224 |     def _calculate_history_score(self, strategy: 'OptimizationStrategy',\n    |                                                   ^^^^^^^^^^^^^^^^^^^^\n225 |                                context_type: ContextType) -> float:\n226 |         \"\"\"Calculate score based on historical performance in this context\"\"\"\n    |\n\nF821 Undefined name `OptimizationStrategy`\n   --> src/knowledge/strategy_selector.py:244:44\n    |\n242 |         return float(np.average(recent_scores, weights=weights))\n243 |     \n244 |     def _record_selection(self, strategy: 'OptimizationStrategy',\n    |                                            ^^^^^^^^^^^^^^^^^^^^\n245 |                          metrics: 'PerformanceMetrics',\n246 |                          context_type: ContextType,\n    |\n\nF821 Undefined name `PerformanceMetrics`\n   --> src/knowledge/strategy_selector.py:245:36\n    |\n244 |     def _record_selection(self, strategy: 'OptimizationStrategy',\n245 |                          metrics: 'PerformanceMetrics',\n    |                                    ^^^^^^^^^^^^^^^^^^\n246 |                          context_type: ContextType,\n247 |                          all_scores: Dict[str, float]) -> None:\n    |\n\nFound 50 errors.\n[*] 21 fixable with the `--fix` option (6 hidden fixes can be enabled with the `--unsafe-fixes` option).\n"
    },
    {
      "check": "MyPy Type Check",
      "error": "Type errors: src/knowledge/format_manager.py:250: error: Missing type parameters for generic type \"Dict\"  [type-arg]\nsrc/knowledge/pattern_library.py:10: error: Function is missing a return type annotation  [no-untyped-def]\nsrc/knowledge/pattern_library.py:10: note: Use \"-> None\" if function does not return a value\nsrc/knowledge/pattern_library.py:13: error: Missing type parameters for generic type \"Dict\"  [type-arg]\nsrc/knowledge/pattern_library.py:328: error: Missing type parameters for generic type \"Dict\"  [type-arg]\nsrc/knowledge/dense_descriptions.py:12: error: Function is missing a return type annotation  [no-untyped-def]\nsrc/knowledge/dense_descriptions.py:12: note: Use \"-> None\" if function does not return a value\nsrc/knowledge/dense_descriptions.py:117: error: \"list[str]\" has no attribute \"replace\"  [attr-defined]\nsrc/knowledge/dense_descriptions.py:183: error: Returning Any from function declared to return \"str | None\"  [no-any-return]\nsrc/knowledge/dense_descriptions.py:347: error: Call to untyped function \"DenseDescriptionGenerator\" in typed context  [no-untyped-call]\nsrc/knowledge/dense_descriptions.py:372: error: Call to untyped function \"DenseDescriptionGenerator\" in typed context  [no-untyped-call]\nsrc/knowledge/patterns/__init__.py:10: error: Function is missing a return type annotation  [no-untyped-def]\nsrc/knowledge/enhanced_patterns.py:12: error: Function is missing a type annotation  [no-untyped-def]\nsrc/knowledge/enhanced_patterns.py:14: error: Call to untyped function \"get_enhanced_patterns\" in typed context  [no-untyped-call]\nsrc/knowledge/optimizer_integration.py:17: error: Cannot assign to a type  [misc]\nsrc/knowledge/optimizer_integration.py:17: error: Incompatible types in assignment (expression has type \"None\", variable has type \"type[ContextDB]\")  [assignment]\nsrc/knowledge/optimizer_integration.py:61: error: Missing type parameters for generic type \"deque\"  [type-arg]\nsrc/knowledge/optimizer_integration.py:273: error: Unsupported left operand type for * (\"object\")  [operator]\nsrc/knowledge/optimizer_integration.py:305: error: Need type annotation for \"context_stats\"  [var-annotated]\nsrc/knowledge/optimizer_integration.py:354: error: Returning Any from function declared to return \"float\"  [no-any-return]\nsrc/knowledge/optimizer_integration.py:370: error: Incompatible return value type (got \"floating[Any] | float\", expected \"float\")  [return-value]\nsrc/knowledge/optimizer_integration.py:375: error: Need type annotation for \"pattern_usage_counts\"  [var-annotated]\nsrc/knowledge/optimizer_integration.py:416: error: Need type annotation for \"strategy_effectiveness\" (hint: \"strategy_effectiveness: dict[<type>, <type>] = ...\")  [var-annotated]\nsrc/knowledge/feedback_loop.py:38: error: Function is missing a return type annotation  [no-untyped-def]\nsrc/knowledge/feedback_loop.py:38: note: Use \"-> None\" if function does not return a value\nsrc/knowledge/feedback_loop.py:39: error: Missing type parameters for generic type \"deque\"  [type-arg]\nsrc/knowledge/feedback_loop.py:53: error: Missing type parameters for generic type \"deque\"  [type-arg]\nsrc/knowledge/feedback_loop.py:54: error: Name \"OptimizationStrategy\" is not defined  [name-defined]\nsrc/knowledge/feedback_loop.py:73: error: Missing type parameters for generic type \"deque\"  [type-arg]\nsrc/knowledge/feedback_loop.py:74: error: Name \"OptimizationStrategy\" is not defined  [name-defined]\nsrc/knowledge/feedback_loop.py:105: error: Name \"PerformanceMetrics\" is not defined  [name-defined]\nsrc/knowledge/feedback_loop.py:106: error: Name \"OptimizationStrategy\" is not defined  [name-defined]\nsrc/knowledge/feedback_loop.py:161: error: Need type annotation for \"context_performance\"  [var-annotated]\nsrc/knowledge/feedback_loop.py:254: error: Name \"OptimizationStrategy\" is not defined  [name-defined]\nsrc/knowledge/optimization/optimization_engine.py:50: error: Function is missing a return type annotation  [no-untyped-def]\nsrc/knowledge/optimization/optimization_engine.py:50: note: Use \"-> None\" if function does not return a value\nsrc/knowledge/optimization/optimization_engine.py:53: error: Need type annotation for \"strategy_history\"  [var-annotated]\nsrc/knowledge/optimization/optimization_engine.py:86: error: callable? not callable  [misc]\nsrc/knowledge/optimization/optimization_engine.py:112: error: Function \"builtins.callable\" is not valid as a type  [valid-type]\nsrc/knowledge/optimization/optimization_engine.py:112: note: Perhaps you meant \"typing.Callable\" instead of \"callable\"?\nsrc/knowledge/optimization/optimization_engine.py:191: error: Argument \"strategy_name\" to \"OptimizationDecision\" has incompatible type \"str | None\"; expected \"str\"  [arg-type]\nsrc/knowledge/optimization/optimization_engine.py:366: error: Returning Any from function declared to return \"float\"  [no-any-return]\nsrc/knowledge/optimization/optimization_engine.py:366: error: No overload variant of \"min\" matches argument types \"floating[Any]\", \"float\"  [call-overload]\nsrc/knowledge/optimization/optimization_engine.py:366: note: Possible overload variants:\nsrc/knowledge/optimization/optimization_engine.py:366: note:     def [SupportsRichComparisonT: SupportsDunderLT[Any] | SupportsDunderGT[Any]] min(SupportsRichComparisonT, SupportsRichComparisonT, /, *_args: SupportsRichComparisonT, key: None = ...) -> SupportsRichComparisonT\nsrc/knowledge/optimization/optimization_engine.py:366: note:     def [_T] min(_T, _T, /, *_args: _T, key: Callable[[_T], SupportsDunderLT[Any] | SupportsDunderGT[Any]]) -> _T\nsrc/knowledge/optimization/optimization_engine.py:366: note:     def [SupportsRichComparisonT: SupportsDunderLT[Any] | SupportsDunderGT[Any]] min(Iterable[SupportsRichComparisonT], /, *, key: None = ...) -> SupportsRichComparisonT\nsrc/knowledge/optimization/optimization_engine.py:366: note:     def [_T] min(Iterable[_T], /, *, key: Callable[[_T], SupportsDunderLT[Any] | SupportsDunderGT[Any]]) -> _T\nsrc/knowledge/optimization/optimization_engine.py:366: note:     def [SupportsRichComparisonT: SupportsDunderLT[Any] | SupportsDunderGT[Any], _T] min(Iterable[SupportsRichComparisonT], /, *, key: None = ..., default: _T) -> SupportsRichComparisonT | _T\nsrc/knowledge/optimization/optimization_engine.py:366: note:     def [_T1, _T2] min(Iterable[_T1], /, *, key: Callable[[_T1], SupportsDunderLT[Any] | SupportsDunderGT[Any]], default: _T2) -> _T1 | _T2\nsrc/knowledge/optimization/optimization_engine.py:429: error: Returning Any from function declared to return \"float\"  [no-any-return]\nsrc/knowledge/optimization/optimization_engine.py:479: error: Returning Any from function declared to return \"float\"  [no-any-return]\nsrc/knowledge/optimization/optimization_engine.py:511: error: Returning Any from function declared to return \"float\"  [no-any-return]\nsrc/knowledge/optimization/optimization_engine.py:513: error: Missing type parameters for generic type \"Dict\"  [type-arg]\nsrc/knowledge/optimization/optimization_engine.py:565: error: Returning Any from function declared to return \"str\"  [no-any-return]\nsrc/knowledge/strategy_selector.py:35: error: Function is missing a return type annotation  [no-untyped-def]\nsrc/knowledge/strategy_selector.py:35: note: Use \"-> None\" if function does not return a value\nsrc/knowledge/strategy_selector.py:68: error: Name \"PerformanceMetrics\" is not defined  [name-defined]\nsrc/knowledge/strategy_selector.py:69: error: Name \"OptimizationStrategy\" is not defined  [name-defined]\nsrc/knowledge/strategy_selector.py:70: error: Name \"OptimizationMode\" is not defined  [name-defined]\nsrc/knowledge/strategy_selector.py:70: error: Name \"OptimizationStrategy\" is not defined  [name-defined]\nsrc/knowledge/strategy_selector.py:85: error: Argument \"key\" to \"max\" has incompatible type overloaded function; expected \"Callable[[str], SupportsDunderLT[Any] | SupportsDunderGT[Any]]\"  [arg-type]\nsrc/knowledge/strategy_selector.py:93: error: Name \"PerformanceMetrics\" is not defined  [name-defined]\nsrc/knowledge/strategy_selector.py:111: error: Name \"OptimizationStrategy\" is not defined  [name-defined]\nsrc/knowledge/strategy_selector.py:112: error: Name \"PerformanceMetrics\" is not defined  [name-defined]\nsrc/knowledge/strategy_selector.py:114: error: Name \"OptimizationMode\" is not defined  [name-defined]\nsrc/knowledge/strategy_selector.py:141: error: Returning Any from function declared to return \"float\"  [no-any-return]\nsrc/knowledge/strategy_selector.py:143: error: Name \"OptimizationStrategy\" is not defined  [name-defined]\nsrc/knowledge/strategy_selector.py:152: error: \"Collection[str]\" has no attribute \"get\"  [attr-defined]\nsrc/knowledge/strategy_selector.py:164: error: Returning Any from function declared to return \"float\"  [no-any-return]\nsrc/knowledge/strategy_selector.py:166: error: Name \"OptimizationStrategy\" is not defined  [name-defined]\nsrc/knowledge/strategy_selector.py:167: error: Name \"PerformanceMetrics\" is not defined  [name-defined]\nsrc/knowledge/strategy_selector.py:194: error: Name \"OptimizationStrategy\" is not defined  [name-defined]\nsrc/knowledge/strategy_selector.py:195: error: Name \"OptimizationMode\" is not defined  [name-defined]\nsrc/knowledge/strategy_selector.py:224: error: Name \"OptimizationStrategy\" is not defined  [name-defined]\nsrc/knowledge/strategy_selector.py:244: error: Name \"OptimizationStrategy\" is not defined  [name-defined]\nsrc/knowledge/strategy_selector.py:245: error: Name \"PerformanceMetrics\" is not defined  [name-defined]\nsrc/knowledge/strategy_selector.py:281: error: Invalid index type \"float\" for \"dict[str, float]\"; expected type \"str\"  [index]\nsrc/knowledge/strategy_selector.py:288: error: Need type annotation for \"strategy_scores\" (hint: \"strategy_scores: dict[<type>, <type>] = ...\")  [var-annotated]\nsrc/knowledge/performance_monitor.py:8: error: Library stubs not installed for \"psutil\"  [import-untyped]\nsrc/knowledge/performance_monitor.py:8: note: Hint: \"python3 -m pip install types-psutil\"\nsrc/knowledge/performance_monitor.py:8: note: (or run \"mypy --install-types\" to install all missing stub packages)\nsrc/knowledge/performance_monitor.py:28: error: Function is missing a return type annotation  [no-untyped-def]\nsrc/knowledge/performance_monitor.py:28: note: Use \"-> None\" if function does not return a value\nsrc/knowledge/performance_monitor.py:29: error: Missing type parameters for generic type \"deque\"  [type-arg]\nsrc/knowledge/performance_monitor.py:30: error: Missing type parameters for generic type \"deque\"  [type-arg]\nsrc/knowledge/performance_monitor.py:122: error: Name \"PerformanceMetrics\" is not defined  [name-defined]\nsrc/knowledge/performance_monitor.py:170: error: Returning Any from function declared to return \"float\"  [no-any-return]\nsrc/knowledge/performance_monitor.py:170: error: No overload variant of \"min\" matches argument types \"floating[Any] | float64\", \"float\"  [call-overload]\nsrc/knowledge/performance_monitor.py:170: note: Possible overload variants:\nsrc/knowledge/performance_monitor.py:170: note:     def [SupportsRichComparisonT: SupportsDunderLT[Any] | SupportsDunderGT[Any]] min(SupportsRichComparisonT, SupportsRichComparisonT, /, *_args: SupportsRichComparisonT, key: None = ...) -> SupportsRichComparisonT\nsrc/knowledge/performance_monitor.py:170: note:     def [_T] min(_T, _T, /, *_args: _T, key: Callable[[_T], SupportsDunderLT[Any] | SupportsDunderGT[Any]]) -> _T\nsrc/knowledge/performance_monitor.py:170: note:     def [SupportsRichComparisonT: SupportsDunderLT[Any] | SupportsDunderGT[Any]] min(Iterable[SupportsRichComparisonT], /, *, key: None = ...) -> SupportsRichComparisonT\nsrc/knowledge/performance_monitor.py:170: note:     def [_T] min(Iterable[_T], /, *, key: Callable[[_T], SupportsDunderLT[Any] | SupportsDunderGT[Any]]) -> _T\nsrc/knowledge/performance_monitor.py:170: note:     def [SupportsRichComparisonT: SupportsDunderLT[Any] | SupportsDunderGT[Any], _T] min(Iterable[SupportsRichComparisonT], /, *, key: None = ..., default: _T) -> SupportsRichComparisonT | _T\nsrc/knowledge/performance_monitor.py:170: note:     def [_T1, _T2] min(Iterable[_T1], /, *, key: Callable[[_T1], SupportsDunderLT[Any] | SupportsDunderGT[Any]], default: _T2) -> _T1 | _T2\nsrc/knowledge/performance_monitor.py:214: error: Value of type variable \"SupportsRichComparisonT\" of \"max\" cannot be \"floating[Any] | float\"  [type-var]\nsrc/knowledge/performance_monitor.py:215: error: Value of type variable \"SupportsRichComparisonT\" of \"max\" cannot be \"floating[Any] | float\"  [type-var]\nsrc/knowledge/performance_monitor.py:217: error: Incompatible return value type (got \"floating[Any] | float\", expected \"float\")  [return-value]\nsrc/knowledge/performance_monitor.py:238: error: Returning Any from function declared to return \"float\"  [no-any-return]\nsrc/knowledge/performance_monitor.py:260: error: Incompatible return value type (got \"floating[Any] | float\", expected \"float\")  [return-value]\nsrc/knowledge/performance_monitor.py:275: error: Incompatible types in assignment (expression has type \"floating[Any]\", variable has type \"float\")  [assignment]\nsrc/knowledge/optimizer.py:59: error: Call to untyped function \"PerformanceMonitor\" in typed context  [no-untyped-call]\nsrc/knowledge/optimizer.py:60: error: Call to untyped function \"StrategySelector\" in typed context  [no-untyped-call]\nsrc/knowledge/optimizer.py:61: error: Call to untyped function \"FeedbackLoop\" in typed context  [no-untyped-call]\nsrc/knowledge/optimizer.py:64: error: Missing type parameters for generic type \"deque\"  [type-arg]\nsrc/knowledge/optimizer.py:308: error: Returning Any from function declared to return \"bool\"  [no-any-return]\nsrc/knowledge/optimization/__init__.py:4: error: Cannot find implementation or library stub for module named \"knowledge.optimization.strategy_algorithms\"  [import-not-found]\nsrc/knowledge/optimization/__init__.py:4: note: See https://mypy.readthedocs.io/en/stable/running_mypy.html#missing-imports\nsrc/knowledge/optimization/__init__.py:5: error: Cannot find implementation or library stub for module named \"knowledge.optimization.performance_predictor\"  [import-not-found]\nsrc/knowledge/tests/test_db_manager.py:12: error: Unused \"type: ignore\" comment  [unused-ignore]\nsrc/knowledge/embeddings.py:25: error: Call to untyped function \"DenseDescriptionGenerator\" in typed context  [no-untyped-call]\nsrc/knowledge/embeddings.py:41: error: Incompatible types in assignment (expression has type \"None\", variable has type \"SentenceTransformer\")  [assignment]\nsrc/knowledge/embeddings.py:107: error: Returning Any from function declared to return \"ndarray[tuple[Any, ...], dtype[Any]]\"  [no-any-return]\nsrc/knowledge/embeddings.py:107: error: \"Tensor\" has no attribute \"astype\"  [attr-defined]\nsrc/knowledge/batch_embeddings.py:120: error: Returning Any from function declared to return \"list[Function]\"  [no-any-return]\nsrc/knowledge/batch_embeddings.py:120: error: \"EmbeddingManager\" has no attribute \"find_similar_functions_with_embedding\"  [attr-defined]\nsrc/knowledge/batch_embeddings.py:128: error: Returning Any from function declared to return \"list[Pattern]\"  [no-any-return]\nsrc/knowledge/batch_embeddings.py:128: error: \"EmbeddingManager\" has no attribute \"find_similar_patterns_with_embedding\"  [attr-defined]\nsrc/knowledge/batch_embeddings.py:230: error: Function is missing a type annotation for one or more arguments  [no-untyped-def]\nsrc/knowledge/batch_embeddings.py:265: error: \"Function\" has no attribute \"similarity\"  [attr-defined]\nsrc/knowledge/batch_embeddings.py:269: error: \"Function\" has no attribute \"similarity\"  [attr-defined]\nsrc/knowledge/batch_embeddings.py:273: error: Function is missing a type annotation for one or more arguments  [no-untyped-def]\nsrc/knowledge/batch_embeddings.py:301: error: \"Pattern\" has no attribute \"similarity\"  [attr-defined]\nsrc/knowledge/batch_embeddings.py:305: error: \"Pattern\" has no attribute \"similarity\"  [attr-defined]\nsrc/knowledge/batch_embeddings.py:310: error: \"type[EmbeddingManager]\" has no attribute \"find_similar_functions_with_embedding\"  [attr-defined]\nsrc/knowledge/batch_embeddings.py:311: error: \"type[EmbeddingManager]\" has no attribute \"find_similar_patterns_with_embedding\"  [attr-defined]\nFound 103 errors in 15 files (checked 28 source files)\n"
    },
    {
      "check": "File Size Critical",
      "error": "Files exceed 500-line absolute max: knowledge/optimizer_integration.py: 522 lines, knowledge/optimization/optimization_engine.py: 596 lines"
    },
    {
      "check": "Project Count Violation",
      "error": "Found 0 projects, expected 5"
    }
  ]
}